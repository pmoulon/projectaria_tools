"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[8684],{15680:(e,t,a)=>{a.r(t),a.d(t,{MDXContext:()=>d,MDXProvider:()=>m,mdx:()=>b,useMDXComponents:()=>p,withMDXComponents:()=>c});var n=a(96540);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var a=arguments[t];for(var n in a)Object.prototype.hasOwnProperty.call(a,n)&&(e[n]=a[n])}return e},o.apply(this,arguments)}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function s(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var d=n.createContext({}),c=function(e){return function(t){var a=p(t.components);return n.createElement(e,o({},t,{components:a}))}},p=function(e){var t=n.useContext(d),a=t;return e&&(a="function"==typeof e?e(t):s(s({},t),e)),a},m=function(e){var t=p(e.components);return n.createElement(d.Provider,{value:t},e.children)},u="mdxType",h={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},f=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,o=e.originalType,i=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),c=p(a),m=r,u=c["".concat(i,".").concat(m)]||c[m]||h[m]||o;return a?n.createElement(u,s(s({ref:t},d),{},{components:a})):n.createElement(u,s({ref:t},d))}));function b(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=a.length,i=new Array(o);i[0]=f;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[u]="string"==typeof e?e:r,i[1]=s;for(var d=2;d<o;d++)i[d]=a[d];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}f.displayName="MDXCreateElement"},59770:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>m,frontMatter:()=>o,metadata:()=>s,toc:()=>d});var n=a(58168),r=(a(96540),a(15680));const o={sidebar_position:60,title:"HOT3D Dataset"},i="HOT3D Dataset",s={unversionedId:"open_datasets/hot3d",id:"open_datasets/hot3d",title:"HOT3D Dataset",description:"HOT3D is a new benchmark dataset for vision-based understanding of 3D hand-object interactions. This dataset contains over 800 minutes of egocentric recordings, with 33 diverse hand-held objects, capturing over one million multi-view frames of hand-object interactions.",source:"@site/docs/open_datasets/hot3d.mdx",sourceDirName:"open_datasets",slug:"/open_datasets/hot3d",permalink:"/projectaria_tools/docs/open_datasets/hot3d",draft:!1,editUrl:"https://github.com/facebookresearch/projectaria_tools/tree/main/website/docs/open_datasets/hot3d.mdx",tags:[],version:"current",sidebarPosition:60,frontMatter:{sidebar_position:60,title:"HOT3D Dataset"},sidebar:"tutorialSidebar",previous:{title:"Ego-Exo4D Data Format and Loader",permalink:"/projectaria_tools/docs/open_datasets/ego-exo4d/ego-exo4d_data_format"},next:{title:"Open Models",permalink:"/projectaria_tools/docs/open_models/"}},l={},d=[{value:"Getting Started",id:"getting-started",level:2},{value:"HOT3D Research Challenges",id:"hot3d-research-challenges",level:2}],c={toc:d},p="wrapper";function m(e){let{components:t,...a}=e;return(0,r.mdx)(p,(0,n.A)({},c,a,{components:t,mdxType:"MDXLayout"}),(0,r.mdx)("h1",{id:"hot3d-dataset"},"HOT3D Dataset"),(0,r.mdx)("p",null,"HOT3D is a new benchmark dataset for vision-based understanding of 3D hand-object interactions. This dataset contains over 800 minutes of egocentric recordings, with 33 diverse hand-held objects, capturing over one million multi-view frames of hand-object interactions."),(0,r.mdx)("p",null,"The dataset contains:"),(0,r.mdx)("ul",null,(0,r.mdx)("li",{parentName:"ul"},"Synchronized multi-view egocentric videos from Project Aria glasses and Quest 3 VR headset"),(0,r.mdx)("li",{parentName:"ul"},"High-quality 3D pose annotations of hands and objects"),(0,r.mdx)("li",{parentName:"ul"},"3D object models with PBR materials"),(0,r.mdx)("li",{parentName:"ul"},"2D bounding boxes"),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("a",{parentName:"li",href:"/projectaria_tools/docs/data_formats/mps/mps_eye_gaze"},"Eye Gaze MPS data")," (Aria only)"),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("a",{parentName:"li",href:"/projectaria_tools/docs/data_formats/mps/slam/mps_pointcloud"},"Semi-Dense Point Cloud MPS data")," (Aria only)")),(0,r.mdx)("p",null,"HOT3D uses its own specific downloader, available in the HOT3D GitHub repository, enabling you to download Quest3, Aria and object models data."),(0,r.mdx)("h2",{id:"getting-started"},"Getting Started"),(0,r.mdx)("ul",null,(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("a",{parentName:"li",href:"https://www.projectaria.com/datasets/hot3D/"},"https://www.projectaria.com/datasets/hot3D/")," - find out more about the dataset and get access to it."),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("a",{parentName:"li",href:"https://arxiv.org/pdf/2406.09598"},"Introducing HOT3D: An Egocentric Dataset for 3D Hand and Object Tracking")," - research paper."),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("a",{parentName:"li",href:"https://github.com/facebookresearch/hot3d"},"HOT3D GitHub repository")," - install HOT3D Python tooling that will enable you to download and visualize HOT3D data.",(0,r.mdx)("ul",{parentName:"li"},(0,r.mdx)("li",{parentName:"ul"},"Use the ",(0,r.mdx)("a",{parentName:"li",href:"https://github.com/facebookresearch/hot3d/blob/main/hot3d/HOT3D_Tutorial.ipynb"},"HOT3D Jupyter notebook tutorial")," to get to know the downloader and visualizers.")))),(0,r.mdx)("h2",{id:"hot3d-research-challenges"},"HOT3D Research Challenges"),(0,r.mdx)("p",null,"HOT3D data is used in the following research challenges:"),(0,r.mdx)("ul",null,(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("a",{parentName:"li",href:"https://github.com/facebookresearch/hand_tracking_toolkit?tab=readme-ov-file#evaluation"},"Multiview Egocentric Hand Tracking Challenge")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("a",{parentName:"li",href:"https://bop.felk.cvut.cz/challenges/bop-challenge-2024/"},"BOP: Benchmark for 6D Object Pose Estimation"))))}m.isMDXComponent=!0}}]);