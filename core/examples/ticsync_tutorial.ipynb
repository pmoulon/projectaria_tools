{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c5c3a33-a812-497a-9e5b-af16bc2dfc73",
   "metadata": {},
   "source": [
    "# Time-Synchronized Recordings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36f5ef501948315",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "* Learn how to validate VRS files recorded in a [TICSync](https://facebookresearch.github.io/projectaria_tools/docs/ARK/sdk/ticsync) session.\n",
    "* Learn how fetch synchronized frames from TICSync VRS files.\n",
    "* Learn how to interpret synchronization offsets amongst the frames of the recordings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5253ab",
   "metadata": {},
   "source": [
    "## Understanding Time Domains\n",
    "\n",
    "In a TICSync recording, all devices mark video frames with a timestamp in a conceptual TICSync time domain. During the recording, the TICSync algorithm constructs, on-the-fly, the mapping between the conceptual TICSync time domain and the concrete `DEVICE_TIME` time domains of the glasses. Under the current implementation, the unique _server_ device uses its `DEVICE_TIME` as the conceptual TICSync time, while all clients use their concrete `TIC_SYNC` time domains. The code below shows how to download TICSync sample recordings (VRS files) and how to query the concrete time domains in the VRS files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77360599",
   "metadata": {},
   "source": [
    "## Python Dependencies\n",
    "\n",
    "1. Set up a Python virtual environment with [this version of Projectaria Tools using pip](https://facebookresearch.github.io/projectaria_tools/docs/data_utilities/installation/installation_python)\n",
    "2. You may have to `pip install matplotlib notebook==6.5.7`. Notebook v7 may have issues.\n",
    "4. `cd ~ && jupyter notebook`.\n",
    "5. Navigate in jupyter's file browser to the location of this notebook\n",
    "\n",
    "Alternatively, try the notebook in colab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2b8b93",
   "metadata": {},
   "source": [
    "## Download Sample TICSync VRS Files\n",
    "\n",
    "We have three sample synchronized recordings of the same millisecond-resolution clock display. The recordings include 3 minutes of simultaneous recording. Some of the recordings are longer than three minutes long because the glasses take time to connect and they start recording sequentially.\n",
    "\n",
    "The files are around 3&nbsp;GB each, so the downloading may take some considerable time. Check your `/tmp/ticsync_sample_data` folder to track download progress. The notebook kernel may appear frozen during the downloads, but it's not. The cell below will finish eventually. \n",
    "\n",
    "The logic checks whether the files have already been downloaded so you only have to wait once, then you can repeatedly run the notebook.\n",
    "\n",
    "If you prefer, you may substitute your own TICSync files for our samples. Just bypass this downloading code (don't run the cells) and adjust the definition of `ticsync_pathnames` as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47384a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from urllib.request import urlretrieve\n",
    "from zipfile import ZipFile\n",
    "\n",
    "google_colab_env = 'google.colab' in str(get_ipython())\n",
    "if google_colab_env:\n",
    "    print(\"Running from Google Colab, installing projectaria_tools and getting sample data\")\n",
    "    !pip install projectaria-tools\n",
    "    ticsync_sample_path = \"./ticsync_sample_data/\"\n",
    "else:\n",
    "    ticsync_sample_path = \"/tmp/ticsync_sample_data/\"\n",
    "\n",
    "base_url = \"https://www.projectaria.com/async/sample/download/?bucket=core&filename=\"\n",
    "os.makedirs(ticsync_sample_path, exist_ok=True)\n",
    "\n",
    "ticsync_filenames = [\n",
    "    \"ticsync_tutorial_server_3m.vrs\",\n",
    "    \"ticsync_tutorial_client1_3m.vrs\",\n",
    "    \"ticsync_tutorial_client2_3m.vrs\",]\n",
    "\n",
    "print(\"Downloading sample data (if they don't already exist)\")\n",
    "for filename in tqdm(ticsync_filenames):\n",
    "    print(f\"Processing: {filename}\")\n",
    "    full_path = os.path.join(ticsync_sample_path, filename)\n",
    "    if os.path.isfile(full_path):\n",
    "        print(f\"{full_path} has alredy been downloaded.\")\n",
    "    else:\n",
    "        print(f\"Downloading {base_url}{filename} to {full_path}\")\n",
    "        urlretrieve(f\"{base_url}{filename}\", full_path)\n",
    "        if filename.endswith(\".zip\"):\n",
    "            with ZipFile(full_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(path=ticsync_sample_path)                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92130649",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c240d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Iterator, Any\n",
    "import rerun as rr\n",
    "\n",
    "from projectaria_tools.core import data_provider\n",
    "from projectaria_tools.core.data_provider import VrsMetadata, MetadataTimeSyncMode\n",
    "from projectaria_tools.core.sensor_data import (\n",
    "    SensorData,\n",
    "    ImageData,\n",
    "    TimeDomain,\n",
    "    TimeQueryOptions,\n",
    ")\n",
    "from projectaria_tools.core.stream_id import StreamId"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2160c5",
   "metadata": {},
   "source": [
    "## Pathname Instructions\n",
    "\n",
    "Adjust the following path names if necessary to accommodate the locations of the files you wish to analyze. These are the only names needed going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256a4a4289f938be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticsync_pathnames = [\n",
    "    os.path.join(ticsync_sample_path, filename)\n",
    "    for filename in ticsync_filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8489522",
   "metadata": {},
   "source": [
    "## Get Data Providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe46842",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_providers = [data_provider.create_vrs_data_provider(filename)\n",
    "                  for filename in ticsync_pathnames]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba947018",
   "metadata": {},
   "source": [
    "## Get and Browse Metadata\n",
    "\n",
    "Let's examine the metadata for one of the providers.\n",
    "\n",
    "The metadata are in a Python object. Here is a way to convert it (or any other object) into a dict for browsing its fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf797991",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_metadata: VrsMetadata = data_providers[0].get_metadata()\n",
    "server_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0306cda0",
   "metadata": {},
   "source": [
    "The metadata have the attribute `time_sync_mode`, which is a Python `enum`. We use its `name` attribute for tests below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7268ab8a4fda74ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(MetadataTimeSyncMode.TicSyncServer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9095d7617157d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_metadata.time_sync_mode.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907b4412099d490d",
   "metadata": {},
   "source": [
    "The other possibilities for `MetadataTimeSyncMode` are `TicSyncClient`, `Ntp`, `Timecode`, and `NotEnabled`. Only `TicSyncServer` and `TicSyncClient` pertain to our investigations, here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5147f1f",
   "metadata": {},
   "source": [
    "## Check that all VRS Files Belong to the Same Session\n",
    "\n",
    "One critical attribute of the metadata is the `shared_session_id`. Your shared recordings must belong to the same shared session. If they do not, the results are nonsense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2349b9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_session_ids(providers:list[data_provider]) -> None:\n",
    "    for provider in providers:\n",
    "        print(f'shared session id = {provider.get_metadata().shared_session_id}')\n",
    "\n",
    "def check_session_ids(providers:list[data_provider]) -> None:\n",
    "    session_ids = [provider.get_metadata().shared_session_id\n",
    "                  for provider in providers]\n",
    "    assert (sid == session_ids[0] for sid in session_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d8a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_session_ids(data_providers)\n",
    "check_session_ids(data_providers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057e686f",
   "metadata": {},
   "source": [
    "We'll use `check_session_ids` in the display codes below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3cc7d0-cc81-4254-a5a2-403a3422729b",
   "metadata": {},
   "source": [
    "## Displaying Frames by Timestamp(ns)\n",
    "\n",
    "First define a `streams` dictionary, which reminds us that there are other synchronized recordings in the VRS files. We use only `\"camera-rgb\"` in this notebook.\n",
    "\n",
    "After these definitions, we'll see how to investigate the synchronized VRS files by timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7c813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's possible to search other image streams.\n",
    "streams = {\n",
    "    \"camera-slam-left\": StreamId(\"1201-1\"),\n",
    "    \"camera-slam-right\":StreamId(\"1201-2\"),\n",
    "    \"camera-rgb\":StreamId(\"214-1\"),\n",
    "    \"camera-eyetracking\":StreamId(\"211-1\"),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7323d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_server_provider(providers:list[data_provider]) -> data_provider:\n",
    "    server_providers = [provider for provider in providers\n",
    "                       if provider.get_metadata().time_sync_mode.name == 'TicSyncServer']\n",
    "    return server_providers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6407221a23da1d",
   "metadata": {},
   "source": [
    "See that it's a valid Python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ab08f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_provider = get_server_provider(data_providers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559ad3478d2ad7c",
   "metadata": {},
   "source": [
    "Get all the timestamps, in nanoseconds, from the reference `DEVICE_TIME` time domain of the server. These are the conceptual TICSync timestamps for the unique, distinguished server device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935a7fea-df53-4bcb-8ad6-fa2cb75439dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_server_timestamps_ns = server_provider.get_timestamps_ns(\n",
    "    streams[\"camera-rgb\"], TimeDomain.DEVICE_TIME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9537b68",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda2ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MS_PER_NS = 1 / 1_000_000\n",
    "\n",
    "def ticsync_time_domain_from_provider(provider:data_provider) -> TimeDomain:\n",
    "    \"\"\"Return a VRS file's local approximation of the conceptual \n",
    "    TICSync time.\"\"\"\n",
    "    mode = provider.get_metadata().time_sync_mode.name\n",
    "    if mode == 'TicSyncServer':\n",
    "        domain = TimeDomain.DEVICE_TIME\n",
    "    elif mode == 'TicSyncClient':\n",
    "        domain = TimeDomain.TIC_SYNC\n",
    "    else:\n",
    "        raise NotImplementedError(f'Unsupported time-sync mode {mode}')\n",
    "    return domain\n",
    "\n",
    "def split_providers(providers:list[data_provider]) -> tuple[data_provider, list[data_provider]]:\n",
    "    \"\"\"A utility function used internally.\"\"\"\n",
    "    server_provider = [provider for provider in providers\n",
    "                       if provider.get_metadata().time_sync_mode.name \n",
    "                          == 'TicSyncServer'][0]\n",
    "    client_providers = [provider for provider in providers\n",
    "                       if provider.get_metadata().time_sync_mode.name \n",
    "                          == 'TicSyncClient']\n",
    "    return server_provider, client_providers\n",
    "    \n",
    "def print_timestamp_offsets_ms(time_ns:int, providers:list[data_provider]) -> None:\n",
    "    \"\"\"We are concerned with the offsets (time differences) between\n",
    "    client glasses and server glasses. Offsets between clients are\n",
    "    not informative, as each client settles to an approximation of\n",
    "    the server's timestamps.\"\"\"\n",
    "    server_provider, client_providers = split_providers(providers)\n",
    "    server_time_ns = get_closest_timestamp_ns(time_ns, server_provider)\n",
    "    client_times_ns = [get_closest_timestamp_ns(time_ns, client_provider)\n",
    "                       for client_provider in client_providers]\n",
    "    for i, client_time_ns in enumerate(client_times_ns):\n",
    "        offset = (client_time_ns - server_time_ns) * MS_PER_NS\n",
    "        print(f'client{i + 1} offset (ms) = {offset}')\n",
    "\n",
    "def get_closest_timestamp_ns(ticsync_time_ns:int, provider:data_provider) -> int:\n",
    "    \"\"\"Return the actual timestamp in a VRS file that's closest\n",
    "    to a given time in nanoseconds.\"\"\"\n",
    "    domain = ticsync_time_domain_from_provider(provider)\n",
    "    return provider.get_sensor_data_by_time_ns(\n",
    "        stream_id=streams[\"camera-rgb\"],\n",
    "        time_ns=ticsync_time_ns,\n",
    "        time_domain=domain,\n",
    "        time_query_options=TimeQueryOptions.CLOSEST).get_time_ns(domain)\n",
    "    \n",
    "def get_closest_image_by_ticsync_time(ticsync_time_ns:int, provider:data_provider) -> ImageData:\n",
    "    \"\"\"Get an image from a VRS file closest in TICSync time to a \n",
    "    given time in nanoseconds.\"\"\"\n",
    "    return provider.get_image_data_by_time_ns(\n",
    "        stream_id=streams[\"camera-rgb\"],\n",
    "        time_ns=ticsync_time_ns,\n",
    "        time_domain=ticsync_time_domain_from_provider(provider),\n",
    "        time_query_options=TimeQueryOptions.CLOSEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6b0ea8",
   "metadata": {},
   "source": [
    "### Show Frames by Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7090047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_frames_by_ticsync_timestamp_ns(ticsync_time_ns:int, providers:list[data_provider]) -> None:\n",
    "    check_session_ids(providers)\n",
    "    images = [get_closest_image_by_ticsync_time(ticsync_time_ns, provider) \n",
    "             for provider in providers]\n",
    "    print_timestamp_offsets_ms(ticsync_time_ns, providers)\n",
    "    fig_m, axes_m = plt.subplots(1, len(providers), figsize=(10, 5), dpi=300)\n",
    "    image_index = 0\n",
    "    for idx, frame in enumerate(images):\n",
    "        axes_m[idx].set_title(providers[idx].get_metadata().time_sync_mode.name)\n",
    "        npa = frame[0].to_numpy_array()\n",
    "        npar = np.rot90(npa, k=1, axes=(1, 0))\n",
    "        axes_m[idx].imshow(npar)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5392c85e4601b08f",
   "metadata": {},
   "source": [
    "### At an Arbitrary Timestamp\n",
    "\n",
    "Arbitrarily, pick a timestamp halfway through the recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17109421-6279-4e61-b8a5-005895f542dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frames_by_ticsync_timestamp_ns(all_server_timestamps_ns[len(all_server_timestamps_ns) // 2], data_providers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0c0c80-ff68-4bab-acc1-f3e0bda18b89",
   "metadata": {},
   "source": [
    "See that they're synchronized to clock time within 16 ms, within one frame of each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241f7e69",
   "metadata": {},
   "source": [
    "## Waiting for TICSync Settling\n",
    "\n",
    "TICSync needs warmup, typically 45 seconds after recording starts for each device to settle. Here is code to show you how to find timestamps after this settling time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa77824",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEC_PER_NS = 1 / 1e9\n",
    "\n",
    "def diff_timestamps_ns_s(t1_ns:int, t2_ns:int) -> int:\n",
    "    return (t1_ns - t2_ns) * SEC_PER_NS\n",
    "\n",
    "def timestamp_ns_after_delay_s(timestamps_ns:list[int], delay_s:int) -> int:\n",
    "    first_timestamp_ns = timestamps_ns[0]\n",
    "    ts_ns = 0\n",
    "    for i, ts_ns in enumerate(timestamps_ns):\n",
    "        if diff_timestamps_ns_s(ts_ns, first_timestamp_ns) >= delay_s:\n",
    "            break\n",
    "    return ts_ns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abde06a",
   "metadata": {},
   "source": [
    "The TICSync time after 45 seconds since last device began recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0597475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticsync_time_ns_after_settlement = max([timestamp_ns_after_delay_s(\n",
    "    provider.get_timestamps_ns(\n",
    "        streams[\"camera-rgb\"], \n",
    "        ticsync_time_domain_from_provider(provider)), 45) \n",
    "    for provider in data_providers])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab1f0ca",
   "metadata": {},
   "source": [
    "That allows us to display the first frames after the delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e18dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frames_by_ticsync_timestamp_ns(ticsync_time_ns_after_settlement, data_providers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f03ba9b",
   "metadata": {},
   "source": [
    "Observe, again, that the offsets are within one frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0accf7a4",
   "metadata": {},
   "source": [
    "## Play Videos in Rerun\n",
    "\n",
    "Rerun is an open-source tool for displaying and manipulating visualizations with interactive tools. The `scrubbing` tool is particularly effective for exploring TICSync timestamps. \n",
    "\n",
    "Rerun can display in an external window with frames fed on-the-fly from the notebook, or Rerun can display directly in the notebook after waiting for all frames of interest to be logged. In this notebook, we demonstrate the displaying of frames in the notebook itself, and we present non-executable instructions for those who would like to display frames in an external window."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9d1b93",
   "metadata": {},
   "source": [
    "### Iterate over all Server Frames\n",
    "\n",
    "Both modes of Rerun--in-notebook and in-external-window--employ a Python iterator over all the server's frames to retrieve frames marked with the TICSync reference timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a2856039975f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reference_iterator(server_provider:data_provider) -> Iterator[SensorData]:\n",
    "    # Set up deliver options for the server VRS data provider.\n",
    "    deliver_option = server_provider.get_default_deliver_queued_options()\n",
    "    # Deactivate all server streams, for a fresh start.\n",
    "    deliver_option.deactivate_stream_all()\n",
    "    # Activate the one camera-rgb stream we care about.\n",
    "    deliver_option.activate_stream(streams[\"camera-rgb\"])\n",
    "    # Create a timestamp-ordered, sensor-data iterator from the server. \n",
    "    # This will work for large streams like the ~4GB VRS files for the\n",
    "    # three-minute videos.\n",
    "    result: Iterator = server_provider.deliver_queued_sensor_data(deliver_option)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203ffa4c",
   "metadata": {},
   "source": [
    "### Starting Rerun\n",
    "\n",
    "Before logging data, it is necessary to start Rerun. The code differs depending on whether you're running Rerun in an external window. If so, change the type of the following cell to `Code` via the `Cell->Cell Type` menu in Jupyter and run it. For colab users and others who prefer an in-notebook display, this code is in a cell of type `Raw`."
   ]
  },
  {
   "cell_type": "raw",
   "id": "cdd0cbd6",
   "metadata": {},
   "source": [
    "rr.init(\"Aria TICSync Visualizer\", spawn=True)\n",
    "rr.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f508382c",
   "metadata": {},
   "source": [
    "To start Rerun for in-notebook display, run the following cell. Run the identical code every time you want a fresh Rerun display in the notebook. Note that Rerun may not display if you're running the notebook in PyCharm. Best to use either colab or the web-based implementation of Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62ab0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.init(\"Aria TICSync Visualizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a1ceb1fb7559b",
   "metadata": {},
   "source": [
    "### log_datum\n",
    "\n",
    "`log_datum`, called by `show_rerun`, pushes images into Rerun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5caa80fdd77f4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_datum(\n",
    "    is_server: bool,\n",
    "    device_nickname: str,  # to ID a device Rerun's display\n",
    "    sensor_name: str,  # e.g., 214-1 for RGB camera\n",
    "    label: str,  # e.g., camera-rgb; for double-checking\n",
    "    datum: SensorData,\n",
    "    timestamp_ns: int,\n",
    ") -> None:\n",
    "    \"\"\"Called by show_rerun.\"\"\"\n",
    "    # Set device_entity for labeling displays in Rerun. \n",
    "    rr.set_time_nanos(\"device_time\", timestamp_ns)\n",
    "    if is_server:\n",
    "        device_entity = \"/server/\" + device_nickname + \"/\" \n",
    "    else:\n",
    "        device_entity = \"/client/\" + device_nickname + \"/\"\n",
    "\n",
    "    rr_stream_name = device_entity + sensor_name\n",
    "    assert \"camera\" in label\n",
    "    # The datum has its image data in slot 0.\n",
    "    image_index = 0\n",
    "    img = datum.image_data_and_record()[image_index].to_numpy_array()\n",
    "    # Rotate the image for readability of the clock.\n",
    "    rotated_img = np.rot90(img, k=1, axes=(1, 0))\n",
    "    rr.log(\n",
    "        rr_stream_name + \"/image\",\n",
    "        rr.Image(rotated_img).compress(jpeg_quality=75),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1740f6f0",
   "metadata": {},
   "source": [
    "### show_rerun\n",
    "\n",
    "`show_rerun` fetches client frames via `get_sensor_data_by_time_ns` in the client's `TIC_SYNC` time domain. Alternatively, one might use `get_closest_image` as we did above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9ee45058e0ce1",
   "metadata": {},
   "source": [
    "#### Nicknames for Rerun Display\n",
    "\n",
    "The last six digits of device serial numbers are a convenient choice for \"nicknames\" for the glasses in the Rerun display. However, nicknames can be anything you like. Change the code below to suit you.\n",
    "\n",
    "`show_rerun` takes a list of providers, a starting timestamp in ns, and a number of frames, defaulting to 300--tens seconds worth at 30 frames per second. If you are running in-notebook, there can be a delay as the iterator moves to the desired timestamp from the beginning of the server file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72303245d7bd21b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_rerun(providers: list[data_provider], start_ticsync_timestamp_ns:int, nframes:int = 300):\n",
    "    check_session_ids(providers)\n",
    "    assert nframes > 0\n",
    "    server_provider, client_providers = split_providers(providers)\n",
    "    server_data_stream = create_reference_iterator(server_provider)\n",
    "    server_nick = server_provider.get_metadata().device_serial[-6:]\n",
    "    client_nicks = [client_provider.get_metadata().device_serial[-6:]\n",
    "                   for client_provider in client_providers]\n",
    "    print(f'{server_nick = }')\n",
    "    print(f'{client_nicks = }')\n",
    "    startframe = 0\n",
    "    for i, server_datum in tqdm(enumerate(server_data_stream)):\n",
    "        # The server datum contains the server image. Get its timestamp,\n",
    "        # in the reference TimeDomain DEVICE_TIME.\n",
    "        server_timestamp_ns = server_datum.get_time_ns(TimeDomain.DEVICE_TIME)\n",
    "        if server_timestamp_ns < start_ticsync_timestamp_ns:\n",
    "            continue\n",
    "        elif startframe == 0:\n",
    "            startframe = i\n",
    "        if (i - startframe) >= nframes:\n",
    "            break\n",
    "        # The rest of these attributes help with labeling the Rerun displays.\n",
    "        stream_id = server_datum.stream_id()  # e.g. 214-1 for the RGB camera.\n",
    "        stream_id_str = str(stream_id)  # as a string\n",
    "        # The following will say \"camera-rgb\", for labeling the Rerun displays.\n",
    "        stream_label = server_provider.get_label_from_stream_id(server_datum.stream_id())\n",
    "        log_datum(\n",
    "            is_server=True,\n",
    "            device_nickname=server_nick,\n",
    "            sensor_name=stream_id_str,\n",
    "            label=stream_label,\n",
    "            datum=server_datum,\n",
    "            timestamp_ns=server_timestamp_ns,)\n",
    "        for i, (nickname, provider) in enumerate(zip(client_nicks, client_providers)):\n",
    "            # Get the closest client sensor datum, in its TIC_SYNC TimeDomain,\n",
    "            # to the server's reference time in its DEVICE_TIME TimeDomain.\n",
    "            client_datum = provider.get_sensor_data_by_time_ns(\n",
    "                stream_id=stream_id,\n",
    "                time_ns=server_timestamp_ns,\n",
    "                time_domain=TimeDomain.TIC_SYNC,\n",
    "                time_query_options=TimeQueryOptions.CLOSEST,\n",
    "            )\n",
    "            # Key the Rerun display of the client image to the client's TIC_SYNC time.\n",
    "            client_timestamp_ns = client_datum.get_time_ns(TimeDomain.TIC_SYNC)\n",
    "            # Log the client image.\n",
    "            log_datum(\n",
    "                is_server=False,\n",
    "                device_nickname=nickname,\n",
    "                sensor_name=stream_id_str,\n",
    "                label=stream_label,\n",
    "                datum=client_datum,\n",
    "                timestamp_ns=client_timestamp_ns,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb7a930c8470fb0",
   "metadata": {},
   "source": [
    "### Show Three Videos\n",
    "\n",
    "In the Rerun display, pan the images by dragging or two-finger scrolling on a trackpad, and zoom the images via pinching on a mac trackpad. Move the scrubbing tool, which appears below the images, to read off TICSync times in hours, minutes, and seconds. These times do not correspond to the times displayed on the real-time clock in the images. \n",
    "\n",
    "The following cell demonstrates 150 frames starting after a quarter of the entire duration. The cell takes about 20 seconds to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77c8459",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.init(\"Aria TICSync Visualizer\")\n",
    "start_time_ns = all_server_timestamps_ns[len(all_server_timestamps_ns) // 4]\n",
    "show_rerun(data_providers, start_time_ns, nframes=150)\n",
    "rr.notebook_show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a26efd0-8bb2-4250-b85b-0e311470f7c2",
   "metadata": {},
   "source": [
    "## Find Frames by Scrubbing in Rerun\n",
    "\n",
    "Use Rerun's scrubbing feature to read off frame times in hours, minutes, and seconds. Display synchronized triplets of frames given timestamps in hours, minutes, seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee79a773807a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_frames_by_h_m_s(hours:int, minutes:int, seconds:int):\n",
    "    NS_PER_S = 1_000_000_000\n",
    "    S_PER_M = 60\n",
    "    S_PER_H = 60 * S_PER_M\n",
    "    time_ns = NS_PER_S * ((hours * S_PER_H) + (minutes * S_PER_M) + seconds)\n",
    "    show_frames_by_ticsync_timestamp_ns(time_ns, data_providers)\n",
    "\n",
    "show_frames_by_h_m_s(9, 22, 54)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e241846009663d85",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Generally speaking, TICSync performs within 1 frame after a 45-second settling time.\n",
    "\n",
    "We have exhibited general tools for displaying and manipulating synchronized data from VRS files. We have shown how to assess the synchronization versus a physical time standard such as a millisecond clock display. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
